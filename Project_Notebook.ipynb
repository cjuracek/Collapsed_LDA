{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Word stemming\n",
    "- Consider removing not *all* numbers; would date numbers/years proabably be important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing + Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import ipdb\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_doc(doc):\n",
    "    '''Convert to lowercase, remove punctuation/whitespace, and split on spaces'''\n",
    "    doc = doc.lower()\n",
    "    punc = string.punctuation.replace('\\'', '')  # Don't remove apostrophes\n",
    "    whitespace = string.whitespace + '\\x03'  # End of file char\n",
    "    \n",
    "    # Convert whitespace/punctuation to spaces, and remove apostophes \n",
    "    translator = str.maketrans(punc + whitespace, ' ' * (len(punc) + len(whitespace)), '\\'')\n",
    "    doc_no_punc = doc.translate(translator)\n",
    "    return doc_no_punc.split()\n",
    "\n",
    "\n",
    "def remove_stop(tokens, stopwords):\n",
    "    return [token for token in tokens if token not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse sgm file for all articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/reuters21578/reut2-000.sgm') as f:\n",
    "    data = f.read()\n",
    "\n",
    "soup = BeautifulSoup(data, features=\"html5lib\")\n",
    "texts = soup.find_all('text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the title + article and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_docs = {}\n",
    "for text in texts:\n",
    "    title = text.findChild('title')\n",
    "    \n",
    "    # Title is non-existent for a few articles\n",
    "    if title:\n",
    "        \n",
    "        # Use contents because the text has no name; always the last element\n",
    "        title_docs[title.string] = text.contents[-1]\n",
    "\n",
    "# Example title: BAHIA COCOA REVIEW\n",
    "title_doc_token = {title: tokenize_doc(doc) for title, doc in title_docs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download()\n",
    "stop_words = stopwords.words('English')\n",
    "stop_words += ['said', 'reuter']\n",
    "\n",
    "# Remove apostrophes; cleaned words have them removed\n",
    "stop_words = set([word.replace('\\'', '') for word in stop_words])\n",
    "title_docs_token_no_stop = {title: remove_stop(tokens, stop_words) for title, tokens in title_doc_token.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Stem each word in each document\n",
    "title_docs_stemmed = {title: [ps.stem(w) for w in doc] for title, doc in title_docs_token_no_stop.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove articles with \"blah blah blah\" as only text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_docs_stemmed = {title: words for title, words in title_docs_stemmed.items() if len(words) != 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_words = set().union(*title_docs_stemmed.values())\n",
    "unique_words = list(unique_words)\n",
    "\n",
    "# Try to convert to number; if it is, we don't want it\n",
    "for num_word in unique_words.copy():\n",
    "    try:\n",
    "        int(num_word)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    for doc, words in title_docs_stemmed.items():\n",
    "        title_docs_stemmed[doc] = [word for word in words if word != num_word]\n",
    "    unique_words.remove(num_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Gibbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 20\n",
    "titles = title_docs_stemmed.keys()\n",
    "document_word_topics = {title: [] for title in titles}  # Contains the ordered list of topics for each document\n",
    "                                                        # Dict of lists\n",
    "    \n",
    "# Counts of each topic per document (dict of dicts)\n",
    "document_topic_counts = {title: dict.fromkeys(range(1, K + 1), 0) for title in titles}\n",
    "word_topic_counts = {word: dict.fromkeys(range(1, K + 1), 0) for word in unique_words}  # Counts of each topic per word (dict of dicts)\n",
    "total_topic_counts = dict.fromkeys(range(1, K + 1), 0)  # Counts of each topic across all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for doc, words in title_docs_stemmed.items():\n",
    "    for i, word in enumerate(words):\n",
    "        topic = np.random.randint(1, K + 1)\n",
    "        document_word_topics[doc].append(topic)\n",
    "        document_topic_counts[doc][topic] = document_topic_counts[doc].get(topic, 0) + 1\n",
    "        word_topic_counts[word][topic] = word_topic_counts[word].get(topic, 0) + 1\n",
    "        total_topic_counts[topic] = total_topic_counts[topic] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics of the word in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 6,\n",
       " 6,\n",
       " 17,\n",
       " 16,\n",
       " 12,\n",
       " 19,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 9,\n",
       " 12,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 11,\n",
       " 3,\n",
       " 13,\n",
       " 4,\n",
       " 18,\n",
       " 18,\n",
       " 17,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 20,\n",
       " 15,\n",
       " 11,\n",
       " 4,\n",
       " 10,\n",
       " 12,\n",
       " 7,\n",
       " 18,\n",
       " 6,\n",
       " 16,\n",
       " 13,\n",
       " 9,\n",
       " 10,\n",
       " 17,\n",
       " 13,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 13,\n",
       " 5,\n",
       " 18,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 20,\n",
       " 15,\n",
       " 1,\n",
       " 2,\n",
       " 15,\n",
       " 4,\n",
       " 20,\n",
       " 20,\n",
       " 1,\n",
       " 19,\n",
       " 4,\n",
       " 14,\n",
       " 18,\n",
       " 3,\n",
       " 10,\n",
       " 4,\n",
       " 16,\n",
       " 13,\n",
       " 6,\n",
       " 13,\n",
       " 15,\n",
       " 14,\n",
       " 20,\n",
       " 9,\n",
       " 15,\n",
       " 20,\n",
       " 15,\n",
       " 5,\n",
       " 7,\n",
       " 15,\n",
       " 5,\n",
       " 18,\n",
       " 5,\n",
       " 13,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 17,\n",
       " 7,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 13,\n",
       " 19,\n",
       " 10,\n",
       " 13,\n",
       " 6,\n",
       " 15,\n",
       " 20,\n",
       " 5,\n",
       " 12,\n",
       " 10,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 10,\n",
       " 1,\n",
       " 13,\n",
       " 19,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 14,\n",
       " 11,\n",
       " 19,\n",
       " 13,\n",
       " 1,\n",
       " 12,\n",
       " 15,\n",
       " 3,\n",
       " 1,\n",
       " 17,\n",
       " 15,\n",
       " 5,\n",
       " 12,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 12,\n",
       " 17,\n",
       " 20,\n",
       " 7,\n",
       " 2,\n",
       " 15,\n",
       " 14,\n",
       " 20,\n",
       " 9,\n",
       " 3,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 13,\n",
       " 3,\n",
       " 20,\n",
       " 4,\n",
       " 15,\n",
       " 2,\n",
       " 15,\n",
       " 20,\n",
       " 18,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 10,\n",
       " 14,\n",
       " 16,\n",
       " 20,\n",
       " 12,\n",
       " 11,\n",
       " 10,\n",
       " 4,\n",
       " 19,\n",
       " 12,\n",
       " 15,\n",
       " 12,\n",
       " 2,\n",
       " 16,\n",
       " 7,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 13,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 18,\n",
       " 12,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 18,\n",
       " 11,\n",
       " 5,\n",
       " 6,\n",
       " 13,\n",
       " 8,\n",
       " 8,\n",
       " 16,\n",
       " 19,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 19,\n",
       " 2,\n",
       " 10,\n",
       " 18,\n",
       " 3,\n",
       " 13,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 11,\n",
       " 15,\n",
       " 3,\n",
       " 12,\n",
       " 13,\n",
       " 16,\n",
       " 8,\n",
       " 6,\n",
       " 12,\n",
       " 10,\n",
       " 7,\n",
       " 4,\n",
       " 15,\n",
       " 20,\n",
       " 17,\n",
       " 13,\n",
       " 1,\n",
       " 4,\n",
       " 18,\n",
       " 6,\n",
       " 11,\n",
       " 16,\n",
       " 18,\n",
       " 6,\n",
       " 4,\n",
       " 15,\n",
       " 2,\n",
       " 1,\n",
       " 15,\n",
       " 18,\n",
       " 10,\n",
       " 13,\n",
       " 16,\n",
       " 6,\n",
       " 4,\n",
       " 16,\n",
       " 15,\n",
       " 20,\n",
       " 16,\n",
       " 12,\n",
       " 20,\n",
       " 20,\n",
       " 1,\n",
       " 17,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 13,\n",
       " 19,\n",
       " 3,\n",
       " 18,\n",
       " 5,\n",
       " 5,\n",
       " 12]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_topics['BAHIA COCOA REVIEW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic distribution in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 17,\n",
       " 2: 16,\n",
       " 3: 15,\n",
       " 4: 18,\n",
       " 5: 17,\n",
       " 6: 14,\n",
       " 7: 14,\n",
       " 8: 12,\n",
       " 9: 12,\n",
       " 10: 13,\n",
       " 11: 8,\n",
       " 12: 16,\n",
       " 13: 19,\n",
       " 14: 6,\n",
       " 15: 21,\n",
       " 16: 14,\n",
       " 17: 9,\n",
       " 18: 15,\n",
       " 19: 10,\n",
       " 20: 19}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_counts['BAHIA COCOA REVIEW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic distributions per word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 4,\n",
       " 2: 4,\n",
       " 3: 4,\n",
       " 4: 2,\n",
       " 5: 2,\n",
       " 6: 2,\n",
       " 7: 4,\n",
       " 8: 0,\n",
       " 9: 2,\n",
       " 10: 1,\n",
       " 11: 1,\n",
       " 12: 0,\n",
       " 13: 3,\n",
       " 14: 1,\n",
       " 15: 2,\n",
       " 16: 1,\n",
       " 17: 1,\n",
       " 18: 2,\n",
       " 19: 2,\n",
       " 20: 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_topic_counts['canada']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total count of all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 3717,\n",
       " 2: 3732,\n",
       " 3: 3742,\n",
       " 4: 3732,\n",
       " 5: 3727,\n",
       " 6: 3584,\n",
       " 7: 3716,\n",
       " 8: 3776,\n",
       " 9: 3635,\n",
       " 10: 3616,\n",
       " 11: 3669,\n",
       " 12: 3787,\n",
       " 13: 3723,\n",
       " 14: 3753,\n",
       " 15: 3752,\n",
       " 16: 3678,\n",
       " 17: 3590,\n",
       " 18: 3691,\n",
       " 19: 3676,\n",
       " 20: 3722}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_topic_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "niter = 10  # Iterations of Gibbs sampler\n",
    "alpha = 1  # Controls topic distribution per document\n",
    "beta = 1  # Controls word distribution per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(niter):\n",
    "    for doc, words in title_docs_stemmed.items():\n",
    "        for i, word in enumerate(words):\n",
    "            #Z = 0\n",
    "            densities = np.zeros(K)\n",
    "            curr_topic = document_word_topics[doc][i]\n",
    "            for k in range(1, K + 1):\n",
    "                N_kj = document_topic_counts[doc].get(k, 0)\n",
    "                N_wk = word_topic_counts[word].get(k, 0)\n",
    "                N_k = total_topic_counts.get(k, 0)\n",
    "                \n",
    "                # New draw is conditioned on everything BUT this observation\n",
    "                if curr_topic == k:\n",
    "                    N_kj -= 1\n",
    "                    N_wk -= 1\n",
    "                    N_k -= 1\n",
    "                    \n",
    "                # Eq. 1\n",
    "                a_kj = N_kj + alpha    \n",
    "                b_wk = (N_wk + beta) / (N_k + W * beta)\n",
    "                \n",
    "                densities[k - 1] = a_kj * b_wk\n",
    "                #Z += a_kj * b_wk\n",
    "                \n",
    "            # Draw a new topic\n",
    "            densities /= np.sum(densities)  # Normalize\n",
    "            new_topic = choices(range(1, K + 1), densities)[0]\n",
    "            \n",
    "            if new_topic == curr_topic:\n",
    "                continue\n",
    "            \n",
    "            # Update counts\n",
    "            document_word_topics[doc][i] = new_topic\n",
    "            \n",
    "            document_topic_counts[doc][curr_topic] -= 1\n",
    "            document_topic_counts[doc][new_topic] += 1\n",
    "            \n",
    "            word_topic_counts[word][curr_topic] -= 1\n",
    "            word_topic_counts[word][new_topic] += 1\n",
    "            \n",
    "            total_topic_counts[curr_topic] -= 1\n",
    "            total_topic_counts[new_topic] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating $\\phi$ and $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an estimate of the marginal posterior distribution of topics, we can get an estimate of:\n",
    "\n",
    "$\\phi_{wk}$: probability of word $w$ given $k$ \n",
    "\n",
    "and \n",
    "\n",
    "$\\theta_{kj}$: mixture component of topic $k$ in document $j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 2: 0,\n",
       " 3: 1,\n",
       " 4: 5,\n",
       " 5: 8,\n",
       " 6: 0,\n",
       " 7: 0,\n",
       " 8: 1,\n",
       " 9: 3,\n",
       " 10: 0,\n",
       " 11: 2,\n",
       " 12: 0,\n",
       " 13: 0,\n",
       " 14: 0,\n",
       " 15: 0,\n",
       " 16: 0,\n",
       " 17: 0,\n",
       " 18: 17,\n",
       " 19: 3,\n",
       " 20: 0}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_topic_counts['canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_matrix = np.zeros((K, W))\n",
    "\n",
    "for w, word in enumerate(unique_words):\n",
    "    for k in range(1, K + 1):\n",
    "        N_wk = word_topic_counts[word][k]\n",
    "        N_k = total_topic_counts[k]\n",
    "        \n",
    "        phi_matrix[k - 1, w] = (N_wk + beta) / (N_k + W * beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_top_words = {}\n",
    "\n",
    "for k in range(K):\n",
    "    phi_k = phi_matrix[k, :]\n",
    "    top_10_idx = np.argsort(phi_k)[::-1][:10]\n",
    "    top_10_words = [unique_words[i] for i in top_10_idx]\n",
    "    topic_top_words[k + 1] = top_10_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['bank',\n",
       "  'billion',\n",
       "  'loan',\n",
       "  'area',\n",
       "  'feder',\n",
       "  'state',\n",
       "  'dlr',\n",
       "  'credit',\n",
       "  'program',\n",
       "  'system'],\n",
       " 2: ['equip',\n",
       "  'l',\n",
       "  'quot',\n",
       "  'bern',\n",
       "  'keidanren',\n",
       "  'previous',\n",
       "  'reiter',\n",
       "  'v',\n",
       "  'gener',\n",
       "  'establish'],\n",
       " 3: ['drug',\n",
       "  'unit',\n",
       "  'ici',\n",
       "  'tax',\n",
       "  'polit',\n",
       "  'parti',\n",
       "  'compani',\n",
       "  'pharmaceut',\n",
       "  'chemlawn',\n",
       "  'call'],\n",
       " 4: ['mln',\n",
       "  'dlr',\n",
       "  'vs',\n",
       "  'ct',\n",
       "  'net',\n",
       "  'shr',\n",
       "  'loss',\n",
       "  'oper',\n",
       "  'share',\n",
       "  'profit'],\n",
       " 5: ['would',\n",
       "  'compani',\n",
       "  'one',\n",
       "  'presid',\n",
       "  'week',\n",
       "  'new',\n",
       "  'two',\n",
       "  'analyst',\n",
       "  'secur',\n",
       "  'market'],\n",
       " 6: ['ton',\n",
       "  'stock',\n",
       "  'short',\n",
       "  'compani',\n",
       "  'januari',\n",
       "  'copper',\n",
       "  'system',\n",
       "  'metal',\n",
       "  'combin',\n",
       "  'increas'],\n",
       " 7: ['price',\n",
       "  'dlr',\n",
       "  'share',\n",
       "  'offer',\n",
       "  'oil',\n",
       "  'quota',\n",
       "  'produc',\n",
       "  'compani',\n",
       "  'agreement',\n",
       "  'inc'],\n",
       " 8: ['subsidiari',\n",
       "  'servic',\n",
       "  'inc',\n",
       "  'j',\n",
       "  'r',\n",
       "  'requir',\n",
       "  'n',\n",
       "  'tobacco',\n",
       "  'reynold',\n",
       "  'chicago'],\n",
       " 9: ['st',\n",
       "  'western',\n",
       "  'pacif',\n",
       "  'inc',\n",
       "  'motor',\n",
       "  'pct',\n",
       "  'canadian',\n",
       "  'senior',\n",
       "  'ab',\n",
       "  'mortgag'],\n",
       " 10: ['construct',\n",
       "  'depart',\n",
       "  'passeng',\n",
       "  'dlr',\n",
       "  'ag',\n",
       "  'spend',\n",
       "  'smoke',\n",
       "  'movement',\n",
       "  'letter',\n",
       "  'dot'],\n",
       " 11: ['nil',\n",
       "  'valu',\n",
       "  'alloc',\n",
       "  'salari',\n",
       "  'around',\n",
       "  'intend',\n",
       "  'spokesman',\n",
       "  'divis',\n",
       "  'sinc',\n",
       "  'rubber'],\n",
       " 12: ['product',\n",
       "  'comput',\n",
       "  'appl',\n",
       "  'new',\n",
       "  'macintosh',\n",
       "  'announc',\n",
       "  'ii',\n",
       "  'softwar',\n",
       "  'farmer',\n",
       "  'mac'],\n",
       " 13: ['issu',\n",
       "  'bond',\n",
       "  'manag',\n",
       "  'secur',\n",
       "  'franc',\n",
       "  'coupon',\n",
       "  'warrant',\n",
       "  'underwrit',\n",
       "  'corpor',\n",
       "  'date'],\n",
       " 14: ['corp',\n",
       "  'compani',\n",
       "  'inc',\n",
       "  'contract',\n",
       "  'futur',\n",
       "  'exchang',\n",
       "  'co',\n",
       "  'unit',\n",
       "  'order',\n",
       "  'purchas'],\n",
       " 15: ['china',\n",
       "  'chip',\n",
       "  'system',\n",
       "  'hotel',\n",
       "  'custom',\n",
       "  'hk',\n",
       "  'design',\n",
       "  'time',\n",
       "  'electr',\n",
       "  'dlr'],\n",
       " 16: ['inc',\n",
       "  'design',\n",
       "  'iran',\n",
       "  'custom',\n",
       "  'feder',\n",
       "  'busi',\n",
       "  'aircraft',\n",
       "  'recommend',\n",
       "  'cover',\n",
       "  'irna'],\n",
       " 17: ['prime',\n",
       "  'medusa',\n",
       "  'immedi',\n",
       "  'gold',\n",
       "  'avail',\n",
       "  'technolog',\n",
       "  'guild',\n",
       "  'softwar',\n",
       "  'feder',\n",
       "  'crude'],\n",
       " 18: ['pct',\n",
       "  'year',\n",
       "  'billion',\n",
       "  'bank',\n",
       "  'u',\n",
       "  'market',\n",
       "  'dlr',\n",
       "  'govern',\n",
       "  'rate',\n",
       "  'price'],\n",
       " 19: ['share',\n",
       "  'manag',\n",
       "  'group',\n",
       "  'brazil',\n",
       "  'debt',\n",
       "  'offer',\n",
       "  'ltd',\n",
       "  'funaro',\n",
       "  'fund',\n",
       "  'dlr'],\n",
       " 20: ['base',\n",
       "  'air',\n",
       "  'special',\n",
       "  'enter',\n",
       "  'union',\n",
       "  'posit',\n",
       "  'fix',\n",
       "  'forc',\n",
       "  'full',\n",
       "  'cairo']}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_wk = phi_matrix[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = np.argsort(phi_wk)[::-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_words = [unique_words[i] for i in top_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['said',\n",
       " 'price',\n",
       " 'countri',\n",
       " 'opec',\n",
       " 'govern',\n",
       " 'say',\n",
       " 'tonn',\n",
       " 'meet',\n",
       " 'last',\n",
       " 'problem']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empir_word_topics = {word: max(counts, key=counts.get) for word, counts in word_topic_counts.items()}\n",
    "#max(word_topic_counts['program'], key=word_topic_counts['program'].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'535e4': 10,\n",
       " 'product': 10,\n",
       " 'therebi': 14,\n",
       " 'simul': 20,\n",
       " 'inexpens': 10,\n",
       " 'chrysler': 10,\n",
       " 'multin': 10,\n",
       " 'hectic': 10,\n",
       " 'bread': 11,\n",
       " 'circul': 10,\n",
       " 'slack': 20,\n",
       " 'disappoint': 8,\n",
       " 'amr': 10,\n",
       " 'program': 10,\n",
       " 'accordingli': 10,\n",
       " 'recur': 12,\n",
       " 'beach': 20,\n",
       " 'inventori': 10,\n",
       " 'tariff': 20,\n",
       " 'humanist': 12,\n",
       " 'dgsg': 20,\n",
       " 'gm': 10,\n",
       " 'ross': 1,\n",
       " 'debat': 16,\n",
       " 'conn': 9,\n",
       " 'sight': 10,\n",
       " 'hugh': 20,\n",
       " 'wallaceburg': 10,\n",
       " 'retriev': 10,\n",
       " 'alan': 10,\n",
       " 'wage': 20,\n",
       " 'bag': 20,\n",
       " 'jacqu': 1,\n",
       " 'publicli': 10,\n",
       " 'symbol': 2,\n",
       " 'monopoli': 10,\n",
       " 'bbc': 11,\n",
       " 'nymex': 10,\n",
       " 'modernis': 10,\n",
       " 'dissatisfact': 10,\n",
       " 'bureaucraci': 20,\n",
       " 'amc': 10,\n",
       " 'avail': 10,\n",
       " 'acquir': 10,\n",
       " 'inspector': 10,\n",
       " 'innov': 15,\n",
       " 'stoneciph': 10,\n",
       " 'marcoss': 1,\n",
       " 'evalu': 13,\n",
       " 'meanwhil': 3,\n",
       " 'copra': 20,\n",
       " 'bumper': 2,\n",
       " 'incept': 10,\n",
       " 'wang': 20,\n",
       " 'gun': 1,\n",
       " 'though': 10,\n",
       " 'express': 20,\n",
       " 'materi': 20,\n",
       " 'distanc': 1,\n",
       " 'forum': 20,\n",
       " 'infrastructur': 20,\n",
       " 'llx': 16,\n",
       " 'vendor': 20,\n",
       " 'carniv': 1,\n",
       " 'authorit': 2,\n",
       " 'comptrol': 8,\n",
       " 'arsarco': 10,\n",
       " 'dynam': 20,\n",
       " 'extent': 10,\n",
       " 'subproduct': 10,\n",
       " 'dole': 1,\n",
       " 'par': 10,\n",
       " 'recent': 10,\n",
       " 'grage': 10,\n",
       " 'carter': 1,\n",
       " 'put': 10,\n",
       " 'zestril': 1,\n",
       " 'ail': 10,\n",
       " 'drawn': 10,\n",
       " 'toronto': 20,\n",
       " 'marin': 1,\n",
       " 'costa': 10,\n",
       " 'h': 10,\n",
       " 'enter': 10,\n",
       " 'tonight': 1,\n",
       " 'tougher': 1,\n",
       " 'nigel': 10,\n",
       " 'note': 10,\n",
       " 'turkey': 1,\n",
       " 'refer': 10,\n",
       " 'steer': 7,\n",
       " 'fuel': 20,\n",
       " 'livestock': 17,\n",
       " 'suffici': 20,\n",
       " 'managership': 7,\n",
       " 'china': 20,\n",
       " 'contract': 20,\n",
       " 'asylum': 17,\n",
       " 'commonwealth': 10,\n",
       " 'instabl': 10,\n",
       " 'septemb': 10,\n",
       " 'assay': 1,\n",
       " 'tire': 10,\n",
       " 'strong': 20,\n",
       " 'wong': 20,\n",
       " 'ilc': 3,\n",
       " 'bracket': 7,\n",
       " 'fran': 10,\n",
       " 'seem': 10,\n",
       " 'respres': 2,\n",
       " 'jim': 10,\n",
       " 'ramda': 7,\n",
       " 'exclud': 10,\n",
       " 'conflict': 20,\n",
       " 'recapitalis': 7,\n",
       " 'kendal': 10,\n",
       " 'rockwel': 11,\n",
       " 'illinoi': 1,\n",
       " 'gruppo': 10,\n",
       " 'freight': 20,\n",
       " 'race': 20,\n",
       " 'accomod': 10,\n",
       " 'reproduc': 17,\n",
       " 'equit': 10,\n",
       " 'rhode': 8,\n",
       " 'contenti': 15,\n",
       " 'stategi': 10,\n",
       " 'valuabl': 20,\n",
       " 'burlington': 2,\n",
       " 'knudsen': 19,\n",
       " 'incx': 8,\n",
       " 'spencer': 2,\n",
       " 'lacklust': 10,\n",
       " 'pork': 1,\n",
       " 'california': 10,\n",
       " 'khalil': 14,\n",
       " 'david': 10,\n",
       " 'mariotim': 20,\n",
       " 'sorg': 16,\n",
       " 'sri': 11,\n",
       " 'ubaf': 20,\n",
       " 'coastal': 10,\n",
       " 'dhiyauldin': 17,\n",
       " 'redirect': 10,\n",
       " 'statment': 10,\n",
       " 'exampl': 10,\n",
       " 'claus': 1,\n",
       " 'lauderdal': 10,\n",
       " 'reconstruct': 20,\n",
       " 'cater': 4,\n",
       " 'repair': 10,\n",
       " 'supermarket': 10,\n",
       " 'rebound': 10,\n",
       " 'euroloan': 10,\n",
       " 'ryoka': 10,\n",
       " 'strike': 10,\n",
       " 'swing': 2,\n",
       " 'lot': 20,\n",
       " 'tylan': 20,\n",
       " 'numer': 10,\n",
       " 'evacu': 10,\n",
       " 'number': 10,\n",
       " 'leach': 10,\n",
       " 'daig': 20,\n",
       " 'sa': 10,\n",
       " 'smallest': 20,\n",
       " 'dislik': 10,\n",
       " 'faa': 2,\n",
       " 'paul': 20,\n",
       " 'miner': 10,\n",
       " 'lire': 8,\n",
       " 'wyrough': 10,\n",
       " 'cap': 10,\n",
       " 'ethylen': 6,\n",
       " 'locat': 10,\n",
       " 'enthusiast': 20,\n",
       " 'volum': 10,\n",
       " 'stapl': 1,\n",
       " 'notic': 12,\n",
       " 'ohar': 20,\n",
       " 'billion': 10,\n",
       " 'upper': 20,\n",
       " 'thre': 16,\n",
       " 'inn': 5,\n",
       " 'corazon': 10,\n",
       " 'rjr': 18,\n",
       " 'houys': 10,\n",
       " 'auditor': 10,\n",
       " 'tenth': 10,\n",
       " 'ms': 10,\n",
       " 'wale': 2,\n",
       " 'sne': 10,\n",
       " 'joliet': 16,\n",
       " 'nonstop': 13,\n",
       " 'pattern': 20,\n",
       " 'mcfadden': 10,\n",
       " 'specif': 10,\n",
       " 'chama': 16,\n",
       " 'analogu': 3,\n",
       " 'herd': 10,\n",
       " 'absenc': 10,\n",
       " 'lb': 20,\n",
       " 'ventil': 10,\n",
       " 'trenton': 2,\n",
       " 'trust': 10,\n",
       " 'iron': 18,\n",
       " 'noland': 4,\n",
       " 'outflow': 8,\n",
       " 'microsoft': 1,\n",
       " 'sunmeal': 20,\n",
       " 'realist': 3,\n",
       " 'torchmark': 12,\n",
       " 'observ': 6,\n",
       " 'skfr': 10,\n",
       " 'atpc': 10,\n",
       " 'patch': 11,\n",
       " 'toledo': 15,\n",
       " 'behalf': 10,\n",
       " 'ventur': 10,\n",
       " 'arithmet': 20,\n",
       " 'wluk': 16,\n",
       " 'amtorg': 10,\n",
       " 'mitchel': 10,\n",
       " 'nbc': 10,\n",
       " 'there': 10,\n",
       " 'quarto': 10,\n",
       " 'estim': 10,\n",
       " 'cypriot': 17,\n",
       " 'extra': 3,\n",
       " 'slowli': 10,\n",
       " 'privat': 10,\n",
       " 'recurr': 10,\n",
       " 'confid': 20,\n",
       " 'ccn': 2,\n",
       " 'rollov': 20,\n",
       " 'bulk': 10,\n",
       " 'handel': 10,\n",
       " 'moreov': 2,\n",
       " 'vacant': 10,\n",
       " 'matsushita': 1,\n",
       " 'pretax': 1,\n",
       " 'insur': 10,\n",
       " 'uae': 10,\n",
       " 'fix': 10,\n",
       " 'fugit': 17,\n",
       " 'rafidain': 10,\n",
       " 'util': 10,\n",
       " 'unnam': 11,\n",
       " 'tuli': 8,\n",
       " 'hostel': 12,\n",
       " 'larri': 10,\n",
       " 'parliament': 10,\n",
       " 'parini': 17,\n",
       " 'client': 10,\n",
       " 'birk': 10,\n",
       " 'fisheri': 4,\n",
       " 'specul': 10,\n",
       " 'reloc': 1,\n",
       " 'polystyren': 10,\n",
       " 'kim': 7,\n",
       " 'cargo': 20,\n",
       " 'for\\x7fth': 10,\n",
       " 'composit': 20,\n",
       " 'valid': 5,\n",
       " 'appear': 10,\n",
       " 'deadlin': 10,\n",
       " 'shipment': 20,\n",
       " 'stronger': 6,\n",
       " 'gradual': 17,\n",
       " 'villag': 10,\n",
       " 'describ': 10,\n",
       " 'shop': 10,\n",
       " 'hotel': 20,\n",
       " 'shoreham': 10,\n",
       " 'stg': 10,\n",
       " 'telact': 10,\n",
       " 'action': 10,\n",
       " 'shorten': 10,\n",
       " 'vast': 10,\n",
       " 'down': 20,\n",
       " 'r': 10,\n",
       " 'adit': 10,\n",
       " 'kiuchi': 10,\n",
       " 'portend': 20,\n",
       " 'surpass': 20,\n",
       " 'societ': 16,\n",
       " 'clot': 1,\n",
       " 'superintend': 20,\n",
       " 'pentagon': 20,\n",
       " 'eye': 10,\n",
       " 'avoid': 10,\n",
       " 'ditch': 4,\n",
       " '3p': 1,\n",
       " 'ten': 10,\n",
       " 'jacobson': 5,\n",
       " 'lagricultur': 1,\n",
       " 'defect': 9,\n",
       " 'stimulu': 10,\n",
       " 'divers': 1,\n",
       " 'idsal': 3,\n",
       " 'murgold': 10,\n",
       " 'fla': 10,\n",
       " 'larosier': 20,\n",
       " 'flare': 10,\n",
       " 'canadian': 20,\n",
       " 'hampshir': 10,\n",
       " 'caiss': 10,\n",
       " 'fertil': 1,\n",
       " 'diagnost': 10,\n",
       " 'mend': 15,\n",
       " 'welsh': 20,\n",
       " 'toni': 17,\n",
       " 'blinker': 10,\n",
       " 'sald': 10,\n",
       " 'anthoni': 8,\n",
       " 'complet': 10,\n",
       " 'bulletin': 10,\n",
       " 'tough': 10,\n",
       " 'undermin': 10,\n",
       " 'semi': 10,\n",
       " 'instanc': 15,\n",
       " 'multilater': 10,\n",
       " 'ahead': 10,\n",
       " 'wi': 14,\n",
       " 'citibank': 17,\n",
       " 'basi': 10,\n",
       " 'magnitud': 20,\n",
       " 'redempt': 10,\n",
       " 'medusa': 20,\n",
       " 'silent': 17,\n",
       " 'shipyard': 8,\n",
       " 'mission': 10,\n",
       " 'boulangeri': 1,\n",
       " 'fundament': 10,\n",
       " 'posit': 10,\n",
       " 'henri': 20,\n",
       " 'risen': 13,\n",
       " 'otherwis': 20,\n",
       " 'daisi': 12,\n",
       " 'abolish': 10,\n",
       " 'advers': 10,\n",
       " 'milan': 19,\n",
       " 'fluor': 9,\n",
       " 'hrw': 1,\n",
       " 'imbal': 17,\n",
       " 'autumn': 10,\n",
       " 'annesthet': 8,\n",
       " 'margaret': 19,\n",
       " 'lesli': 3,\n",
       " 'impli': 20,\n",
       " 'distrubut': 10,\n",
       " 'dam': 20,\n",
       " 'videotron': 20,\n",
       " 'leventh': 10,\n",
       " 'mileag': 20,\n",
       " 'civil': 20,\n",
       " '5p': 1,\n",
       " 'realiti': 13,\n",
       " 'season': 10,\n",
       " 'artif': 10,\n",
       " 'reopen': 16,\n",
       " 'aircraft': 1,\n",
       " 'jeffrey': 17,\n",
       " 'area': 20,\n",
       " 'health': 10,\n",
       " 'bullion': 10,\n",
       " 'poct': 20,\n",
       " 'colombian': 10,\n",
       " 'depos': 10,\n",
       " 'deal': 10,\n",
       " 'spring': 20,\n",
       " 'dlr': 10,\n",
       " 'plight': 7,\n",
       " 'crown': 20,\n",
       " 'special': 20,\n",
       " 'selloff': 10,\n",
       " 'prioriti': 5,\n",
       " 'wuerttemberg': 10,\n",
       " 'mae': 10,\n",
       " 'sluggish': 10,\n",
       " 'nbfi': 10,\n",
       " 'santo': 17,\n",
       " 'manufacturng': 20,\n",
       " 'vs': 1,\n",
       " 'valley': 6,\n",
       " 'partisan': 17,\n",
       " 'manifest': 15,\n",
       " 'consult': 10,\n",
       " 'aim': 10,\n",
       " 'easter': 20,\n",
       " 'februari': 10,\n",
       " 'settlement': 20,\n",
       " 'cogener': 10,\n",
       " 'violat': 10,\n",
       " 'internazional': 10,\n",
       " 'blockbust': 9,\n",
       " 'deni': 20,\n",
       " 'turnarouond': 20,\n",
       " 'attend': 10,\n",
       " 'heinl': 1,\n",
       " '1st': 3,\n",
       " 'irna': 10,\n",
       " 'lobbyist': 10,\n",
       " 'justifi': 1,\n",
       " 'weiss': 10,\n",
       " 'yoshiro': 7,\n",
       " 'trader': 10,\n",
       " 'newsprint': 10,\n",
       " 'neutrogena': 20,\n",
       " 'omb': 10,\n",
       " 'chapter': 4,\n",
       " 'yeutter': 10,\n",
       " 'chip': 10,\n",
       " 'bp': 10,\n",
       " 'light': 10,\n",
       " 'ye': 10,\n",
       " 'olin': 7,\n",
       " 'filter': 1,\n",
       " 'nausea': 10,\n",
       " 'gcc': 20,\n",
       " 'andrew': 10,\n",
       " 'ceuta': 20,\n",
       " 'ceo': 15,\n",
       " 'print': 10,\n",
       " 'upset': 10,\n",
       " 'koppaberg': 10,\n",
       " 'warsaw': 20,\n",
       " 'janney': 10,\n",
       " 'bil': 10,\n",
       " 'determin': 10,\n",
       " 'usingpric': 10,\n",
       " 'propect': 10,\n",
       " 'wetex': 5,\n",
       " 'leverag': 10,\n",
       " 'rare': 10,\n",
       " 'mclaughlin': 16,\n",
       " 'do': 10,\n",
       " 'arrang': 10,\n",
       " 'extens': 20,\n",
       " 'women': 10,\n",
       " 'absb': 10,\n",
       " 'bate': 10,\n",
       " 'evergo': 20,\n",
       " 'petroleo': 16,\n",
       " 'leucadia': 9,\n",
       " 'banponc': 12,\n",
       " 'slightli': 10,\n",
       " 'lanka': 17,\n",
       " 'vissanji': 12,\n",
       " 'patron': 20,\n",
       " 'balanc': 10,\n",
       " 'northeast': 10,\n",
       " 'nar': 10,\n",
       " 'spanish': 10,\n",
       " 'diminish': 3,\n",
       " 'superannu': 1,\n",
       " 'tillag': 7,\n",
       " 'full': 10,\n",
       " 'arbitr': 17,\n",
       " 'unequivoc': 13,\n",
       " 'pond': 2,\n",
       " 'scientif': 10,\n",
       " 'euronot': 10,\n",
       " 'war': 10,\n",
       " 'rapese': 20,\n",
       " 'temper': 20,\n",
       " 'quarterli': 10,\n",
       " 'faith': 20,\n",
       " 'indonesia': 10,\n",
       " 'chemic': 10,\n",
       " 'reiter': 20,\n",
       " 'overflow': 10,\n",
       " 'editor': 10,\n",
       " 'pertain': 10,\n",
       " 'accomplish': 10,\n",
       " 'metropolitan': 20,\n",
       " 'massiv': 17,\n",
       " 'hemispher': 5,\n",
       " 'logician': 10,\n",
       " 'mcgraw': 20,\n",
       " 'michael': 20,\n",
       " 'clive': 10,\n",
       " 'soar': 10,\n",
       " 'javier': 1,\n",
       " 'unsolicit': 10,\n",
       " 'crowd': 10,\n",
       " 'micro': 10,\n",
       " 'maverick': 10,\n",
       " 'birmingham': 3,\n",
       " 'distinct': 10,\n",
       " 'grade': 10,\n",
       " 'rica': 10,\n",
       " 'venezuala': 20,\n",
       " 'jean': 1,\n",
       " 'offtak': 8,\n",
       " 'aground': 6,\n",
       " 'assembl': 10,\n",
       " 'look': 10,\n",
       " 'wilson': 20,\n",
       " 'low': 10,\n",
       " 'long': 10,\n",
       " 'duncan': 10,\n",
       " 'sikorski': 20,\n",
       " 'petit': 10,\n",
       " 'canal': 2,\n",
       " 'caught': 19,\n",
       " 'paid': 10,\n",
       " 'shrinkag': 11,\n",
       " 'prescript': 6,\n",
       " 'strength': 10,\n",
       " 'scandal': 10,\n",
       " 'flour': 6,\n",
       " 'cross': 6,\n",
       " 'm2': 10,\n",
       " 'assur': 10,\n",
       " 'undervalu': 10,\n",
       " 'futur': 10,\n",
       " 'sinnificantli': 10,\n",
       " 'soften': 17,\n",
       " 'atlant': 1,\n",
       " 'conceal': 10,\n",
       " 'guag': 13,\n",
       " 'arc': 11,\n",
       " 'edison': 10,\n",
       " 'iraq': 10,\n",
       " 'london': 10,\n",
       " 'inspect': 1,\n",
       " 'sincer': 20,\n",
       " 'poor': 10,\n",
       " 'palm': 20,\n",
       " 'nation': 10,\n",
       " 'goal': 2,\n",
       " 'silverman': 7,\n",
       " 'finger': 10,\n",
       " 'textron': 10,\n",
       " 'extern': 10,\n",
       " 'condemn': 10,\n",
       " 'rothschild': 8,\n",
       " 'mandela': 1,\n",
       " 'fluid': 10,\n",
       " 'block': 1,\n",
       " 'camdessu': 20,\n",
       " 'computerland': 20,\n",
       " 'seaforth': 14,\n",
       " 'pessimist': 7,\n",
       " 'howard': 10,\n",
       " 'ershad': 1,\n",
       " 'techic': 7,\n",
       " 'agreemat': 20,\n",
       " 'teach': 10,\n",
       " 'treasur': 10,\n",
       " 'dearth': 10,\n",
       " 'remodel': 1,\n",
       " 'cera': 10,\n",
       " 'classifi': 10,\n",
       " 'arbitrag': 3,\n",
       " 'shipbuild': 20,\n",
       " 'soyproduct': 6,\n",
       " 'batter': 10,\n",
       " 'chad': 16,\n",
       " 'line': 10,\n",
       " 'zimbabw': 18,\n",
       " 'aris': 20,\n",
       " 'dh': 1,\n",
       " 'bale': 10,\n",
       " 'offic': 10,\n",
       " 'retail': 10,\n",
       " 'wish': 1,\n",
       " 'exact': 10,\n",
       " 'true': 10,\n",
       " 'declin': 20,\n",
       " 'task': 1,\n",
       " 'hed': 10,\n",
       " 'riversid': 15,\n",
       " 'merchant': 1,\n",
       " 'insuffici': 10,\n",
       " 'wedndsday': 20,\n",
       " 'topic': 10,\n",
       " 'hutchison': 20,\n",
       " 'back': 10,\n",
       " 'owe': 10,\n",
       " 'view': 10,\n",
       " 'bakeri': 10,\n",
       " 'rico': 1,\n",
       " 'featur': 10,\n",
       " 'slm': 5,\n",
       " 'cent': 10,\n",
       " 'august': 10,\n",
       " 'garment': 20,\n",
       " 'send': 10,\n",
       " 'crusher': 20,\n",
       " 'wing': 10,\n",
       " 'drawdown': 16,\n",
       " 'miami': 5,\n",
       " 'wife': 10,\n",
       " 'remedi': 10,\n",
       " 'oversubscrib': 20,\n",
       " 'nwa': 10,\n",
       " 'asea': 10,\n",
       " 'progress': 10,\n",
       " 'per': 10,\n",
       " 'btu': 10,\n",
       " 'balladur': 10,\n",
       " 'parent': 1,\n",
       " 'fifth': 10,\n",
       " 'modern': 10,\n",
       " 'femal': 10,\n",
       " 'commonli': 10,\n",
       " 'mull': 3,\n",
       " 'penser': 10,\n",
       " 'malawi': 1,\n",
       " 'procu': 20,\n",
       " 'coven': 16,\n",
       " 'roch': 1,\n",
       " 'reevalu': 10,\n",
       " 'lubbck': 15,\n",
       " 'concess': 10,\n",
       " 'ecuador': 10,\n",
       " 'load': 10,\n",
       " 'greek': 1,\n",
       " 'worri': 10,\n",
       " 'banknot': 10,\n",
       " 'hurri': 10,\n",
       " 'job': 10,\n",
       " 'keycorp': 15,\n",
       " 'dr': 10,\n",
       " 'bahrain': 10,\n",
       " 'boycott': 20,\n",
       " 'inclus': 12,\n",
       " 'read': 10,\n",
       " 'fujitsuka': 10,\n",
       " 'polici': 10,\n",
       " 'hit': 20,\n",
       " 'loser': 4,\n",
       " 'bureaucrat': 6,\n",
       " 'nigeria': 20,\n",
       " 'amend': 10,\n",
       " 'hoc': 5,\n",
       " 'edmonton': 10,\n",
       " 'aluminiumwerk': 8,\n",
       " 'dat': 10,\n",
       " 'climb': 10,\n",
       " 'overtim': 20,\n",
       " 'prepar': 10,\n",
       " 'tanurah': 20,\n",
       " 'ayal': 10,\n",
       " 'kilogram': 17,\n",
       " 'cftc': 6,\n",
       " 'perkin': 1,\n",
       " 'smb': 10,\n",
       " 'protein': 12,\n",
       " 'ar': 12,\n",
       " 'bunya': 10,\n",
       " 'fund': 10,\n",
       " 'probat': 10,\n",
       " 'begin': 10,\n",
       " 'went': 10,\n",
       " 'type': 20,\n",
       " 'delic': 17,\n",
       " 'unchang': 20,\n",
       " 'schult': 10,\n",
       " 'srw': 1,\n",
       " 'pfizer': 8,\n",
       " 'understand': 10,\n",
       " 'monochrom': 1,\n",
       " 'mismatch': 20,\n",
       " 'schoufour': 3,\n",
       " 'rank': 20,\n",
       " 'diskett': 10,\n",
       " 'cabot': 12,\n",
       " 'earliest': 10,\n",
       " 'sometim': 1,\n",
       " 'factual': 10,\n",
       " 'greater': 10,\n",
       " 'enlarg': 20,\n",
       " 'bankruptci': 20,\n",
       " 'west': 10,\n",
       " 'entrant': 20,\n",
       " 'smelter': 20,\n",
       " 'corp': 10,\n",
       " 'primarili': 10,\n",
       " 'credenti': 17,\n",
       " 'lure': 10,\n",
       " 'botch': 10,\n",
       " 'reason': 10,\n",
       " 'regret': 10,\n",
       " 'unless': 10,\n",
       " 'guilder': 20,\n",
       " 'nine': 10,\n",
       " 'lambert': 10,\n",
       " 'lyng': 10,\n",
       " 'esop': 16,\n",
       " 'mario': 20,\n",
       " 'reassert': 10,\n",
       " 'wci': 10,\n",
       " 'zapata': 10,\n",
       " 'sit': 10,\n",
       " 'lever': 20,\n",
       " 'buoyanc': 2,\n",
       " 'revis': 10,\n",
       " 'bess': 8,\n",
       " 'challeng': 10,\n",
       " 'schultz': 3,\n",
       " 'mother': 5,\n",
       " 'scognamiglio': 10,\n",
       " 'intervent': 10,\n",
       " 'style': 20,\n",
       " 'overse': 10,\n",
       " 'moister': 10,\n",
       " 'carryforward': 1,\n",
       " 'recoveri': 10,\n",
       " 'lal': 10,\n",
       " 'witter': 1,\n",
       " 'appalachian': 14,\n",
       " 'march': 10,\n",
       " 'admininstr': 2,\n",
       " 'samoa': 10,\n",
       " 'rehabilit': 10,\n",
       " 'interact': 10,\n",
       " 'tangibl': 10,\n",
       " 'larg': 10,\n",
       " 'froze': 20,\n",
       " 'azpurua': 20,\n",
       " 'orthoped': 11,\n",
       " 'stamp': 10,\n",
       " 'milwauke': 10,\n",
       " 'sail': 17,\n",
       " 'leav': 10,\n",
       " 'naval': 11,\n",
       " 'shaken': 20,\n",
       " 'adolf': 1,\n",
       " 'smith': 20,\n",
       " 'clone': 17,\n",
       " 'truste': 10,\n",
       " 'marvin': 10,\n",
       " 'statew': 10,\n",
       " 'pap': 7,\n",
       " 'guin': 14,\n",
       " 'margarin': 10,\n",
       " 'kane': 16,\n",
       " 'coconut': 20,\n",
       " 'intral': 10,\n",
       " 'sino': 18,\n",
       " 'steam': 10,\n",
       " 'cattl': 6,\n",
       " 'amarlo': 20,\n",
       " 'minut': 10,\n",
       " 'oppos': 10,\n",
       " 'crossroad': 20,\n",
       " 'roaster': 10,\n",
       " 'soymeal': 1,\n",
       " 'admir': 11,\n",
       " 'credit': 10,\n",
       " 'nicaraguan': 10,\n",
       " 'week': 20,\n",
       " 'pariba': 10,\n",
       " 'teleconferenc': 18,\n",
       " 'pierc': 1,\n",
       " 'flat': 10,\n",
       " 'tripl': 2,\n",
       " 'indosuez': 8,\n",
       " 'deleg': 10,\n",
       " 'becam': 10,\n",
       " 'arab': 10,\n",
       " 'ig': 1,\n",
       " 'character': 20,\n",
       " 'resid': 7,\n",
       " 'explain': 10,\n",
       " 'western': 3,\n",
       " 'wangle': 20,\n",
       " 'republican': 10,\n",
       " 'sham': 10,\n",
       " 'nervous': 10,\n",
       " 'slot': 8,\n",
       " 'inaccur': 20,\n",
       " 'semiconductor': 10,\n",
       " 'polyethylen': 5,\n",
       " 'aid': 10,\n",
       " 'maintain': 10,\n",
       " 'lp': 10,\n",
       " 'els': 2,\n",
       " 'bougainvil': 10,\n",
       " 'kit': 10,\n",
       " 'untap': 20,\n",
       " 'teapa': 10,\n",
       " 'prejudic': 20,\n",
       " 'shanghai': 10,\n",
       " 'stabil': 10,\n",
       " 'tellurid': 20,\n",
       " 'weinberg': 2,\n",
       " 'launch': 10,\n",
       " 'seen': 10,\n",
       " 'tabloid': 10,\n",
       " 'den': 8,\n",
       " 'autom': 10,\n",
       " 'file': 10,\n",
       " 'anr': 1,\n",
       " 'kroner': 6,\n",
       " 'huntsvil': 6,\n",
       " 'chaotic': 1,\n",
       " 'seren': 20,\n",
       " 'varieti': 10,\n",
       " 'wolff': 1,\n",
       " 'lock': 3,\n",
       " 'breakup': 10,\n",
       " 'hollands': 17,\n",
       " 'kaya': 12,\n",
       " 'clarifi': 1,\n",
       " 'algeria': 3,\n",
       " 'chevron': 10,\n",
       " 'yearago': 12,\n",
       " 'abc': 1,\n",
       " 'contel': 20,\n",
       " 'length': 6,\n",
       " 'cfm': 6,\n",
       " 'ottawa': 1,\n",
       " 'anti': 10,\n",
       " 'occurr': 20,\n",
       " 'gatess': 1,\n",
       " 'resel': 1,\n",
       " 'industrialist': 7,\n",
       " 'immin': 10,\n",
       " 'eurof': 10,\n",
       " 'someth': 3,\n",
       " 'primari': 20,\n",
       " 'enockson': 9,\n",
       " 'recov': 10,\n",
       " 'revalu': 1,\n",
       " 'highest': 2,\n",
       " 'satisfact': 3,\n",
       " 'reinforc': 7,\n",
       " 'arsenio': 10,\n",
       " 'chines': 20,\n",
       " 'come': 20,\n",
       " 'roadway': 20,\n",
       " 'trojan': 20,\n",
       " 'furiou': 10,\n",
       " 'wheatgrow': 20,\n",
       " 'zero': 20,\n",
       " 'profession': 10,\n",
       " 'aftermarket': 9,\n",
       " 'east': 20,\n",
       " 'corpor': 10,\n",
       " 'amgen': 10,\n",
       " 'danish': 10,\n",
       " 'coast': 20,\n",
       " 'herbicid': 20,\n",
       " 'satellit': 20,\n",
       " 'settl': 10,\n",
       " 'joint': 10,\n",
       " 'sarasota': 15,\n",
       " 'unoc': 10,\n",
       " 'sale': 10,\n",
       " 'smile': 10,\n",
       " 'cope': 10,\n",
       " 'difficulti': 10,\n",
       " 'neighbor': 10,\n",
       " 'candid': 10,\n",
       " 'ingvar': 9,\n",
       " 'compact': 10,\n",
       " 'dredg': 10,\n",
       " 'heavi': 10,\n",
       " 'stuart': 10,\n",
       " 'string': 1,\n",
       " 'offshor': 10,\n",
       " 'fernando': 10,\n",
       " 'rail': 20,\n",
       " 'yard': 17,\n",
       " 'pringl': 18,\n",
       " 'montreal': 10,\n",
       " 'capozza': 1,\n",
       " 'current': 10,\n",
       " 'residenti': 10,\n",
       " 'athen': 10,\n",
       " 'lauri': 10,\n",
       " 'shi': 9,\n",
       " 'pesticid': 5,\n",
       " 'takeov': 10,\n",
       " 'warfar': 14,\n",
       " 'insist': 7,\n",
       " 'chen': 20,\n",
       " 'auction': 20,\n",
       " 'pepsico': 20,\n",
       " 'boesz': 10,\n",
       " 'conceiv': 20,\n",
       " 'drove': 10,\n",
       " 'bcom': 14,\n",
       " 'frederik': 17,\n",
       " 'compos': 10,\n",
       " 'bongard': 10,\n",
       " 'react': 10,\n",
       " 'fenton': 12,\n",
       " 'anita': 20,\n",
       " 'specialti': 10,\n",
       " 'epac': 10,\n",
       " 'accept': 20,\n",
       " 'beyond': 10,\n",
       " 'subdu': 5,\n",
       " 'satisfi': 4,\n",
       " '9p': 1,\n",
       " 'revolutionari': 4,\n",
       " 'lenghten': 20,\n",
       " 'roadslip': 11,\n",
       " 'alcan': 8,\n",
       " 'glenmora': 1,\n",
       " 'aviat': 1,\n",
       " 'milk': 20,\n",
       " 'crystal': 10,\n",
       " 'balli': 17,\n",
       " 'astonish': 4,\n",
       " 'imp': 3,\n",
       " 'emul': 9,\n",
       " 'turner': 10,\n",
       " 'narusawa': 6,\n",
       " 'fenner': 6,\n",
       " 'cargil': 3,\n",
       " 'forward': 20,\n",
       " 'creditor': 10,\n",
       " 'intermediari': 20,\n",
       " 'seafar': 9,\n",
       " 'vdo': 10,\n",
       " 'everi': 20,\n",
       " 'btom': 11,\n",
       " 'placement': 10,\n",
       " 'warren': 10,\n",
       " 'erad': 5,\n",
       " 'germani': 20,\n",
       " 'toshin': 13,\n",
       " 'teck': 10,\n",
       " 'review': 10,\n",
       " 'reput': 10,\n",
       " 'renouf': 6,\n",
       " 'nabisco': 9,\n",
       " 'inland': 10,\n",
       " 'dispos': 3,\n",
       " 'misappl': 7,\n",
       " 'trickl': 16,\n",
       " 'payer': 15,\n",
       " 'underst': 1,\n",
       " 'amen': 4,\n",
       " 'bombay': 10,\n",
       " 'ste': 11,\n",
       " 'purif': 10,\n",
       " 'atmospher': 12,\n",
       " 'carbid': 1,\n",
       " 'pathet': 3,\n",
       " 'element': 10,\n",
       " 'cra': 10,\n",
       " 'barclay': 20,\n",
       " 'due': 10,\n",
       " 'compris': 10,\n",
       " 'way': 20,\n",
       " 'philadelphia': 10,\n",
       " 'amapa': 10,\n",
       " 'favour': 10,\n",
       " 'regim': 1,\n",
       " 'slap': 20,\n",
       " 'repeatedli': 1,\n",
       " 'flash': 10,\n",
       " 'unveil': 10,\n",
       " 'stood': 10,\n",
       " 'raider': 1,\n",
       " 'ineffici': 20,\n",
       " 'refocus': 10,\n",
       " 'rent': 1,\n",
       " 'sporti': 10,\n",
       " 'gloeilampenfabrieken': 16,\n",
       " 'ankara': 10,\n",
       " 'hypertens': 20,\n",
       " 'lightweight': 15,\n",
       " 'aapl': 1,\n",
       " 'araki': 10,\n",
       " 'lie': 10,\n",
       " 'southeastern': 7,\n",
       " 'allegedli': 17,\n",
       " 'amplifi': 20,\n",
       " 'fine': 10,\n",
       " 'collater': 10,\n",
       " 'formalis': 3,\n",
       " 'let': 10,\n",
       " 'clnical': 10,\n",
       " 'weekend': 10,\n",
       " 'bother': 10,\n",
       " 'winter': 10,\n",
       " 'defer': 10,\n",
       " 'larsen': 10,\n",
       " 'touch': 20,\n",
       " 'toward': 20,\n",
       " 'stave': 10,\n",
       " 'unsold': 10,\n",
       " 'stepp': 10,\n",
       " 'disposit': 1,\n",
       " 'abut': 10,\n",
       " 'lake': 14,\n",
       " 'entrepreneur': 10,\n",
       " 'pel': 15,\n",
       " 'mass': 20,\n",
       " 'totter': 20,\n",
       " 'permit': 10,\n",
       " 'liebert': 20,\n",
       " ...}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empir_word_topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
